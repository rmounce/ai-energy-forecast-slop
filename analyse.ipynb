{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Configure Plotly to work in the notebook\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Cell 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "MODEL_TO_ANALYZE = 'price'\n",
    "log_file = f'{MODEL_TO_ANALYZE}_forecast_log.csv'\n",
    "\n",
    "# --- SET THIS TO THE DATE/TIME YOU DEPLOYED THE NEW MODEL ---\n",
    "# Use ISO 8601 format with timezone.\n",
    "ANALYSIS_START_TIME = '2025-07-26T13:45:00+00:00'\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Load the main configuration file to find adjuster paths\n",
    "import json\n",
    "with open('config.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Cell 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(log_file)\n",
    "\n",
    "# Convert timestamp columns\n",
    "df['forecast_target_time'] = pd.to_datetime(df['forecast_target_time'], format='ISO8601')\n",
    "df['forecast_creation_time'] = pd.to_datetime(df['forecast_creation_time'], format='ISO8601')\n",
    "\n",
    "# --- FILTERING: Only analyze forecasts created after the specified start time ---\n",
    "df = df[df['forecast_creation_time'] >= pd.to_datetime(ANALYSIS_START_TIME)].copy()\n",
    "print(f\"Filtered to {len(df)} records created after {ANALYSIS_START_TIME}\")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "df.set_index('forecast_target_time', inplace=True)\n",
    "df.dropna(subset=['actual'], inplace=True) # Drop only if the main model's actual is missing\n",
    "\n",
    "# Calculate the main model's error\n",
    "df['error'] = df['prediction'] - df['actual']\n",
    "\n",
    "print(f\"Prepared {len(df)} records for the '{MODEL_TO_ANALYZE}' model.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Cell 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_adjustments_for_analysis(df, config):\n",
    "    \"\"\"\n",
    "    Reads adjuster profiles and applies them to the raw forecast columns\n",
    "    in the DataFrame, creating new '_adjusted' columns.\n",
    "    \"\"\"\n",
    "    print(\"Applying adjustments on-the-fly for analysis...\")\n",
    "    df_adj = df.copy()\n",
    "    \n",
    "    if 'adjusters' not in config:\n",
    "        print(\"No 'adjusters' config found. Skipping.\")\n",
    "        return df_adj\n",
    "\n",
    "    # Create the 'time_of_day' column needed for mapping\n",
    "    df_adj['target_time_of_day'] = df_adj.index.time.astype(str)\n",
    "\n",
    "    for cov_name, adjuster_config in config['adjusters'].items():\n",
    "        forecast_col = cov_name\n",
    "        adjusted_col = f\"{cov_name}_adjusted\"\n",
    "        \n",
    "        # Load the adjuster profile from its JSON file\n",
    "        try:\n",
    "            with open(adjuster_config['path'], 'r') as f:\n",
    "                profile = json.load(f)\n",
    "            print(f\"- Loaded profile for '{cov_name}'\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"- Profile for '{cov_name}' not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create a mapping from time string to adjustment value\n",
    "        adjustment_map = pd.Series(profile)\n",
    "        \n",
    "        if adjuster_config['type'] == 'additive':\n",
    "            adjustments = df_adj['target_time_of_day'].map(adjustment_map).fillna(0)\n",
    "            df_adj[adjusted_col] = df_adj[forecast_col] + adjustments\n",
    "        elif adjuster_config['type'] == 'multiplicative':\n",
    "            adjustments = df_adj['target_time_of_day'].map(adjustment_map).fillna(1.0)\n",
    "            df_adj[adjusted_col] = df_adj[forecast_col] * adjustments\n",
    "\n",
    "    return df_adj\n",
    "\n",
    "# Run the function to create our analysis-ready DataFrame\n",
    "df_analysis = apply_adjustments_for_analysis(df, CONFIG)\n",
    "\n",
    "# Display the new columns to verify\n",
    "cols_to_show = ['power_pv', 'power_pv_adjusted', 'power_pv_actual']\n",
    "df_analysis[cols_to_show].dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(df['actual'], df['prediction'])\n",
    "rmse = np.sqrt(mean_squared_error(df['actual'], df['prediction']))\n",
    "\n",
    "print(f\"Overall Model Performance ({MODEL_TO_ANALYZE}):\")\n",
    "print(f\"-----------------------------------\")\n",
    "print(f\"Mean Absolute Error (MAE):   {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                    subplot_titles=(f'{MODEL_TO_ANALYZE.capitalize()} Forecast vs. Actual', 'Prediction Error (Residuals)'),\n",
    "                    vertical_spacing=0.1)\n",
    "\n",
    "# Plot 1: Prediction vs Actual\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['actual'], name='Actual', mode='lines',\n",
    "                         line=dict(color='blue', width=2)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['prediction'], name='Prediction', mode='lines',\n",
    "                         line=dict(color='red', dash='dot', width=2)), row=1, col=1)\n",
    "\n",
    "# Plot 2: Error\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['error'], name='Error', mode='lines',\n",
    "                         line=dict(color='purple', width=1)), row=2, col=1)\n",
    "fig.add_hline(y=0, line_width=2, line_dash=\"dash\", line_color=\"green\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Model Performance Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='error', nbins=100,\n",
    "                   title=f'Histogram of Prediction Errors for {MODEL_TO_ANALYZE.capitalize()} Model')\n",
    "fig.update_layout(xaxis_title=\"Prediction Error (Prediction - Actual)\", yaxis_title=\"Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an 'hour' column from the index\n",
    "df['hour'] = df.index.hour\n",
    "\n",
    "# Calculate the average absolute error for each hour\n",
    "hourly_error = df.groupby('hour')['error'].apply(lambda x: np.mean(np.abs(x))).reset_index()\n",
    "\n",
    "fig = px.bar(hourly_error, x='hour', y='error',\n",
    "             title=f'Average Absolute Error by Hour of Day ({MODEL_TO_ANALYZE.capitalize()})')\n",
    "fig.update_layout(xaxis_title=\"Hour of Day\", yaxis_title=\"Mean Absolute Error\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model version and calculate metrics for each\n",
    "performance_by_version = df.groupby('model_version').apply(\n",
    "    lambda g: pd.Series({\n",
    "        'MAE': mean_absolute_error(g['actual'], g['prediction']),\n",
    "        'RMSE': np.sqrt(mean_squared_error(g['actual'], g['prediction'])),\n",
    "        'record_count': len(g)\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "print(\"--- Model Performance by Version ---\")\n",
    "performance_by_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Cell 8: Feature Engineering for Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Feature Engineering (on the main DataFrame) ---\n",
    "\n",
    "# Calculate the forecast horizon (lead time) for each prediction\n",
    "delta = df.index - df['forecast_creation_time']\n",
    "\n",
    "# Round the forecast horizon UP to the nearest 30-minute interval\n",
    "df['forecast_horizon_hours'] = np.ceil(delta.dt.total_seconds() / 1800) / 2\n",
    "\n",
    "# Extract the time component from the target time (e.g., 14:30:00)\n",
    "df['target_time_of_day'] = df.index.time\n",
    "\n",
    "print(\"Feature engineering complete. 'forecast_horizon_hours' and 'target_time_of_day' are now in the main DataFrame.\")\n",
    "\n",
    "\n",
    "# --- Step 2: Define the SIMPLIFIED Analysis Function ---\n",
    "\n",
    "def analyze_forecast_accuracy(df_prepared, prediction_col, actual_col, analysis_name):\n",
    "    \"\"\"\n",
    "    Generates and displays a full accuracy analysis (metrics and heatmaps).\n",
    "    \n",
    "    NOTE: This function now ASSUMES the input DataFrame already contains\n",
    "    'forecast_horizon_hours' and 'target_time_of_day' columns.\n",
    "    \"\"\"\n",
    "    # Create a working copy, keeping the essential columns for this analysis\n",
    "    cols_to_keep = [prediction_col, actual_col, 'forecast_horizon_hours', 'target_time_of_day']\n",
    "    analysis_df = df_prepared[cols_to_keep].copy()\n",
    "    \n",
    "    analysis_df.dropna(subset=[prediction_col, actual_col], inplace=True)\n",
    "\n",
    "    if analysis_df.empty:\n",
    "        print(f\"\\nNo data available for analysis: {analysis_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # --- Metrics ---\n",
    "    mae = mean_absolute_error(analysis_df[actual_col], analysis_df[prediction_col])\n",
    "    rmse = np.sqrt(mean_squared_error(analysis_df[actual_col], analysis_df[prediction_col]))\n",
    "    print(f\"\\n--- Performance Analysis for: {analysis_name} ---\")\n",
    "    print(f\"MAE: {mae:.4f} | RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # --- Error Calculation (the only feature it creates itself) ---\n",
    "    analysis_df['error'] = analysis_df[prediction_col] - analysis_df[actual_col]\n",
    "    \n",
    "    # --- Heatmap 1: Error Magnitude ---\n",
    "    heatmap_mae = pd.pivot_table(analysis_df, values='error', index='target_time_of_day',\n",
    "                                 columns='forecast_horizon_hours', aggfunc=lambda x: np.mean(np.abs(x)))\n",
    "    fig_mae = px.imshow(heatmap_mae, labels=dict(x=\"Forecast Horizon (Hours)\", y=\"Time of Day\", color=\"MAE\"),\n",
    "                        title=f\"<b>Error Magnitude (MAE) for {analysis_name}</b>\", aspect='auto')\n",
    "    fig_mae.update_yaxes(tickformat='%H:%M', autorange=\"reversed\")\n",
    "    fig_mae.show()\n",
    "    \n",
    "    # --- Heatmap 2: Error Bias ---\n",
    "    heatmap_bias = pd.pivot_table(analysis_df, values='error', index='target_time_of_day',\n",
    "                                  columns='forecast_horizon_hours', aggfunc=np.mean)\n",
    "    fig_bias = px.imshow(heatmap_bias, labels=dict(x=\"Forecast Horizon (Hours)\", y=\"Time of Day\", color=\"Mean Error\"),\n",
    "                         title=f\"<b>Error Bias (Mean Error) for {analysis_name}</b>\", aspect='auto',\n",
    "                         color_continuous_scale='RdBu_r', color_continuous_midpoint=0)\n",
    "    fig_bias.update_yaxes(tickformat='%H:%M', autorange=\"reversed\")\n",
    "    fig_bias.show()\n",
    "\n",
    "print(\"Analysis function is now defined and ready to use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Cell 9: Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Engineering for Heatmaps (Run on the final analysis DF) ---\n",
    "delta = df_analysis.index - df_analysis['forecast_creation_time']\n",
    "df_analysis['forecast_horizon_hours'] = np.ceil(delta.dt.total_seconds() / 1800) / 2\n",
    "if 'target_time_of_day' not in df_analysis.columns:\n",
    "     df_analysis['target_time_of_day'] = df_analysis.index.time\n",
    "print(\"Feature engineering for heatmaps complete.\")\n",
    "\n",
    "# ---\n",
    "# --- 1. Analysis of Your Main Model (Price or Load)\n",
    "# ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYZING MAIN MODEL FORECAST\")\n",
    "print(\"=\"*50)\n",
    "analyze_forecast_accuracy(df_analysis, 'prediction', 'actual', f\"Main {MODEL_TO_ANALYZE.capitalize()} Model\")\n",
    "\n",
    "# ---\n",
    "# --- 2. Analysis of Covariate Forecasts (Before vs. After Adjustment)\n",
    "# ---\n",
    "for cov_name in CONFIG.get('adjusters', {}):\n",
    "    raw_forecast_col = cov_name\n",
    "    adj_forecast_col = f\"{cov_name}_adjusted\"\n",
    "    actual_col = f\"{cov_name}_actual\"\n",
    "    \n",
    "    # Check if all necessary columns exist before proceeding\n",
    "    if all(c in df_analysis.columns for c in [raw_forecast_col, adj_forecast_col, actual_col]):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"ANALYZING: {cov_name.upper()}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Analyze the RAW forecast from the provider (e.g., Solcast, BOM)\n",
    "        analyze_forecast_accuracy(df_analysis, raw_forecast_col, actual_col, f\"Raw {cov_name.title()} Forecast\")\n",
    "        \n",
    "        # Analyze YOUR ADJUSTED forecast\n",
    "        analyze_forecast_accuracy(df_analysis, adj_forecast_col, actual_col, f\"AI-Adjusted {cov_name.title()} Forecast\")\n",
    "    else:\n",
    "        print(f\"\\nSkipping analysis for {cov_name} due to missing columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-energy-forecast-slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
